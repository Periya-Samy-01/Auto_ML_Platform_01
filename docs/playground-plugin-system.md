# Playground Plugin System â€” Implementation Plan

> A comprehensive guide to the plugin-based architecture for the AutoML Playground workflow execution system.

---

## Table of Contents

1. [Overview](#overview)
2. [Core Concepts](#core-concepts)
3. [Plugin System Architecture](#plugin-system-architecture)
4. [Node Types & Inspector Behavior](#node-types--inspector-behavior)
5. [Data Flow Through Nodes](#data-flow-through-nodes)
6. [Folder Structure](#folder-structure)
7. [API Contracts](#api-contracts)
8. [Workflow Execution Flow](#workflow-execution-flow)
9. [Implementation Phases](#implementation-phases)

---

## Overview

The Playground is a visual workflow builder where users construct ML pipelines by connecting nodes. Each node represents a step in the ML workflow:

```
Dataset â†’ Preprocessing â†’ Train/Test Split â†’ Model â†’ Evaluate â†’ Visualize
```

The **Plugin System** enables:
- Backend-driven configuration (frontend displays what backend exposes)
- Model-specific evaluation metrics and visualizations
- Easy addition of new algorithms without frontend changes
- Separation of concerns between UI and ML logic

---

## Core Concepts

### 1. Nodes
Visual blocks on the canvas representing workflow steps. Each node has:
- **Type**: dataset, preprocessing, split, model, evaluate, visualize
- **Config**: User-selected options stored in node data
- **Status**: not-configured, configured, running, completed, error

### 2. Edges
Connections between nodes defining data flow. Each edge:
- Connects a source node's output to a target node's input
- Carries metadata about what data passes through
- Validates compatibility between connected nodes

### 3. Plugins
Self-contained modules that define an ML algorithm's complete behavior:
- Hyperparameter schema
- Training logic
- Supported evaluation metrics
- Supported visualizations

### 4. Capabilities
Metadata that flows downstream from Model node to Evaluate/Visualize nodes:
- Which metrics the selected algorithm supports
- Which visualizations are available
- Default selections for each

---

## Plugin System Architecture

### Design Principles

| Principle | Description |
|-----------|-------------|
| **Backend Authority** | Backend plugins define all available options; frontend renders them dynamically |
| **Model-Centric** | Each model plugin declares its compatible metrics and visualizations |
| **Shared Utilities** | Common evaluation and visualization functions live in shared libraries |
| **Hot-Pluggable** | New plugins can be added without modifying core code |

### Plugin Responsibilities

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         MODEL PLUGIN                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  1. METADATA                                                        â”‚
â”‚     â”œâ”€â”€ Name, slug, description, icon                               â”‚
â”‚     â”œâ”€â”€ Problem types: [classification, regression]                 â”‚
â”‚     â””â”€â”€ Category: tree, linear, ensemble, neural                    â”‚
â”‚                                                                     â”‚
â”‚  2. HYPERPARAMETERS                                                 â”‚
â”‚     â”œâ”€â”€ Main parameters (always visible)                            â”‚
â”‚     â”œâ”€â”€ Advanced parameters (collapsible)                           â”‚
â”‚     â””â”€â”€ Field types: int, float, select, bool, range                â”‚
â”‚                                                                     â”‚
â”‚  3. TRAINING                                                        â”‚
â”‚     â”œâ”€â”€ Model instantiation with hyperparameters                    â”‚
â”‚     â”œâ”€â”€ Fit on training data                                        â”‚
â”‚     â””â”€â”€ Return trained model artifact                               â”‚
â”‚                                                                     â”‚
â”‚  4. EVALUATION (declares supported metrics)                         â”‚
â”‚     â”œâ”€â”€ Default metrics to select                                   â”‚
â”‚     â”œâ”€â”€ All supported metrics                                       â”‚
â”‚     â””â”€â”€ References shared evaluator functions                       â”‚
â”‚                                                                     â”‚
â”‚  5. VISUALIZATION (declares supported plots)                        â”‚
â”‚     â”œâ”€â”€ Default plots to select                                     â”‚
â”‚     â”œâ”€â”€ All supported plots                                         â”‚
â”‚     â””â”€â”€ References shared visualizer functions                      â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Shared Libraries

Plugins reference shared utilities rather than implementing their own:

**Evaluators (shared/evaluators.py)**
- `accuracy()`, `f1_score()`, `precision()`, `recall()`
- `roc_auc()`, `confusion_matrix()`, `classification_report()`
- `mse()`, `rmse()`, `mae()`, `r2_score()`

**Visualizers (shared/visualizers.py)**
- `plot_confusion_matrix()`, `plot_roc_curve()`
- `plot_feature_importance()`, `plot_learning_curve()`
- `plot_shap_summary()`, `plot_partial_dependence()`
- `plot_residuals()`, `plot_prediction_vs_actual()`

Each plugin declares WHICH of these it supports, and the shared library handles execution.

---

## Node Types & Inspector Behavior

### Dataset Node

**Purpose**: Select a dataset for the workflow

**Inspector Sections**:
| Section | Behavior |
|---------|----------|
| Dataset Selection | Tabs for "My Datasets" and "Sample Data". Search filter. Radio selection. Upload redirect button. |
| Dataset Preview | Overview: shape, size. Target column selector. Problem type selector. Columns tab: list with types and missing %. |
| Status | Shows configuration state with appropriate icon and message |

**Outputs**:
- Dataset ID
- Problem type (classification/regression/clustering)
- Target column
- Column metadata (names, types, missing percentages)

---

### Preprocessing Node

**Purpose**: Transform and clean data before training

**Inspector Sections**:
| Section | Behavior |
|---------|----------|
| Input Dataset | Shows connected upstream dataset info |
| Operations Pipeline | Orderable list of operations. Add via dropdown grouped by category. Each operation expands to show configuration. |
| Preview | Lists transformations in execution order |
| Warnings | Smart warnings for potential issues |

**Operation Categories**:
- **Missing Values**: Fill (mean, median, mode, constant), Drop rows/columns
- **Scaling**: StandardScaler, MinMaxScaler, RobustScaler
- **Encoding**: OneHotEncoder, LabelEncoder, TargetEncoder
- **Outliers**: IQR removal, Z-score removal, Clipping
- **Other**: Remove duplicates, Drop columns

**Outputs**:
- Ordered list of operations with their configurations
- Column transformations applied

---

### Train/Test Split Node

**Purpose**: Split data into training and testing sets

**Inspector Sections**:
| Section | Behavior |
|---------|----------|
| Input Dataset | Shows connected upstream info |
| Split Configuration | Slider (10-50%), preset buttons (80/20, 70/30, 90/10) |
| Options | Stratify (classification only), Shuffle, Random seed with regenerate |
| Preview | Visual bar, row counts, class distribution if stratified |
| Warnings | Small test set, imbalanced classes, shuffle disabled |

**Outputs**:
- Test size percentage
- Stratify flag
- Shuffle flag
- Random seed

---

### Model Node

**Purpose**: Select and configure an ML algorithm

**Inspector Sections**:
| Section | Behavior |
|---------|----------|
| Algorithm Selection | Radio list of available algorithms filtered by problem type. Shows icon, name, description, "best for" info. |
| Hyperparameters | Dynamic fields from plugin schema. Main + Advanced toggle. Validation warnings. |
| Training Settings | Cross-validation toggle with fold count. Optuna HPO toggle with trials and metric. |
| Cost Estimate | Estimated credits based on configuration |

**Key Behavior**:
- Algorithm list filtered by upstream problem type
- Hyperparameter fields rendered dynamically from plugin schema
- Generates `capabilities` object passed to downstream Evaluate/Visualize nodes

**Outputs**:
- Algorithm ID
- Hyperparameters
- Training settings (CV, Optuna)
- Capabilities (supported metrics + visualizations)

---

### Evaluate Node

**Purpose**: Select metrics to evaluate model performance

**Inspector Sections**:
| Section | Behavior |
|---------|----------|
| Connected Model | Shows upstream model info |
| Evaluation Metrics | Checkbox list from capabilities. Grouped: Recommended + Additional. Quick actions: Select Defaults/All/Clear. |
| Options | Confidence intervals toggle, Compare with baseline toggle |

**Key Behavior**:
- Only shows metrics declared by upstream Model plugin
- Groups metrics into "Recommended" (defaults) and "Additional"
- Each metric shows direction indicator (higher/lower is better)

**Outputs**:
- Selected metric keys
- Option flags

---

### Visualize Node

**Purpose**: Select visualizations to generate

**Inspector Sections**:
| Section | Behavior |
|---------|----------|
| Connected Model | Shows upstream model info |
| Visualizations | Checkbox list from capabilities. Grouped: Recommended / Performance / Explainability. Shows cost per plot. Quick actions. |
| Cost Summary | Total credits for selected visualizations |

**Key Behavior**:
- Only shows plots declared by upstream Model plugin
- Auto-populates defaults when Evaluate node selections change
- Each plot shows credit cost

**Outputs**:
- Selected plot keys
- Total visualization cost

---

## Data Flow Through Nodes

### Canvas-Time Data Flow (Configuration)

During canvas editing, data flows downstream to configure inspector options:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     problemType      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Dataset  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶  â”‚  Model   â”‚  (filters available algorithms)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     targetColumn     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â”‚
                                        â”‚ capabilities
                                        â–¼
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚    Evaluate      â”‚  (shows model-specific metrics)
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â”‚
                                        â”‚ capabilities + selectedMetrics
                                        â–¼
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚   Visualize      â”‚  (shows model-specific plots)
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Implementation**: When edges connect nodes, upstream config propagates to downstream nodes via:
1. Zustand store updates
2. React context or prop drilling
3. Edge metadata carrying capability info

### Execution-Time Data Flow (Runtime)

During workflow execution, actual data flows through the pipeline:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     DataFrame        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     DataFrame
â”‚ Dataset  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶  â”‚ Preprocessing â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                          â”‚
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   X_train, X_test    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   trained_model
â”‚  Split   â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶  â”‚  Model   â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   y_train, y_test    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â”‚
                                        â”‚ model + test data
                                        â–¼
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   metrics_dict
                              â”‚    Evaluate      â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â”‚
                                        â”‚ model + data + metrics
                                        â–¼
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   plot_artifacts
                              â”‚   Visualize      â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Folder Structure

### Backend (apps/api)

```
apps/api/app/
â”œâ”€â”€ plugins/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ registry.py              # Plugin discovery and registration
â”‚   â”œâ”€â”€ base.py                  # BaseModelPlugin abstract class
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                  # Model plugins
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ random_forest.py
â”‚   â”‚   â”œâ”€â”€ xgboost.py
â”‚   â”‚   â”œâ”€â”€ logistic_regression.py
â”‚   â”‚   â”œâ”€â”€ gradient_boosting.py
â”‚   â”‚   â”œâ”€â”€ decision_tree.py
â”‚   â”‚   â”œâ”€â”€ svm.py
â”‚   â”‚   â”œâ”€â”€ knn.py
â”‚   â”‚   â””â”€â”€ linear_regression.py
â”‚   â”‚
â”‚   â””â”€â”€ shared/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ evaluators.py        # All evaluation metric functions
â”‚       â”œâ”€â”€ visualizers.py       # All visualization functions
â”‚       â””â”€â”€ constants.py         # Metric/plot definitions
â”‚
â”œâ”€â”€ preprocessing/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ registry.py              # Preprocessing method registry
â”‚   â”œâ”€â”€ base.py                  # BasePreprocessor abstract class
â”‚   â”‚
â”‚   â”œâ”€â”€ methods/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ missing.py           # FillMissing, DropMissing
â”‚   â”‚   â”œâ”€â”€ scaling.py           # StandardScaler, MinMaxScaler, RobustScaler
â”‚   â”‚   â”œâ”€â”€ encoding.py          # OneHotEncoder, LabelEncoder
â”‚   â”‚   â”œâ”€â”€ outliers.py          # IQROutlier, ZScoreOutlier
â”‚   â”‚   â””â”€â”€ cleaning.py          # RemoveDuplicates, DropColumns
â”‚   â”‚
â”‚   â””â”€â”€ pipeline.py              # PreprocessingPipeline executor
â”‚
â”œâ”€â”€ workflows/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ router.py                # Workflow API endpoints
â”‚   â”œâ”€â”€ schemas.py               # Pydantic models for workflow config
â”‚   â”œâ”€â”€ executor.py              # Workflow execution orchestrator
â”‚   â”œâ”€â”€ validator.py             # Workflow validation logic
â”‚   â””â”€â”€ models.py                # SQLAlchemy models for workflow storage
â”‚
â””â”€â”€ ml/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ trainers/                # Training logic (uses plugins)
    â”œâ”€â”€ evaluators/              # Evaluation execution
    â””â”€â”€ visualizers/             # Visualization generation
```

### Frontend (apps/web)

```
apps/web/
â”œâ”€â”€ app/
â”‚   â””â”€â”€ dashboard/
â”‚       â””â”€â”€ playground/
â”‚           â”œâ”€â”€ layout.tsx
â”‚           â””â”€â”€ page.tsx         # Main playground canvas
â”‚
â”œâ”€â”€ components/
â”‚   â””â”€â”€ playground/
â”‚       â”œâ”€â”€ index.ts             # Exports
â”‚       â”‚
â”‚       â”œâ”€â”€ canvas/
â”‚       â”‚   â”œâ”€â”€ Canvas.tsx           # ReactFlow wrapper
â”‚       â”‚   â”œâ”€â”€ CanvasToolbar.tsx    # Top toolbar with node menu
â”‚       â”‚   â”œâ”€â”€ CanvasStatusBar.tsx  # Bottom status bar
â”‚       â”‚   â””â”€â”€ CanvasMinimap.tsx    # Minimap component
â”‚       â”‚
â”‚       â”œâ”€â”€ nodes/
â”‚       â”‚   â”œâ”€â”€ index.ts
â”‚       â”‚   â”œâ”€â”€ BaseNode.tsx         # Shared node wrapper
â”‚       â”‚   â”œâ”€â”€ DatasetNode.tsx
â”‚       â”‚   â”œâ”€â”€ PreprocessingNode.tsx
â”‚       â”‚   â”œâ”€â”€ SplitNode.tsx
â”‚       â”‚   â”œâ”€â”€ ModelNode.tsx
â”‚       â”‚   â”œâ”€â”€ EvaluateNode.tsx
â”‚       â”‚   â””â”€â”€ VisualizeNode.tsx
â”‚       â”‚
â”‚       â”œâ”€â”€ inspectors/
â”‚       â”‚   â”œâ”€â”€ index.ts
â”‚       â”‚   â”œâ”€â”€ InspectorPanel.tsx   # Right-side inspector container
â”‚       â”‚   â”œâ”€â”€ DatasetInspector.tsx
â”‚       â”‚   â”œâ”€â”€ PreprocessingInspector.tsx
â”‚       â”‚   â”œâ”€â”€ SplitInspector.tsx
â”‚       â”‚   â”œâ”€â”€ ModelInspector.tsx
â”‚       â”‚   â”œâ”€â”€ EvaluateInspector.tsx
â”‚       â”‚   â”œâ”€â”€ VisualizeInspector.tsx
â”‚       â”‚   â”‚
â”‚       â”‚   â””â”€â”€ fields/              # Reusable form field components
â”‚       â”‚       â”œâ”€â”€ index.ts
â”‚       â”‚       â”œâ”€â”€ SliderField.tsx
â”‚       â”‚       â”œâ”€â”€ SelectField.tsx
â”‚       â”‚       â”œâ”€â”€ CheckboxField.tsx
â”‚       â”‚       â”œâ”€â”€ NumberField.tsx
â”‚       â”‚       â””â”€â”€ DynamicField.tsx # Renders field based on schema
â”‚       â”‚
â”‚       â””â”€â”€ execution/
â”‚           â”œâ”€â”€ ExecutionPanel.tsx   # Execution progress UI
â”‚           â”œâ”€â”€ ResultsPanel.tsx     # Display results after execution
â”‚           â””â”€â”€ NodeStatusOverlay.tsx # Status indicators on nodes
â”‚
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ plugins/
â”‚       â”œâ”€â”€ index.ts             # Plugin type definitions
â”‚       â””â”€â”€ types.ts             # TypeScript interfaces
â”‚
â”œâ”€â”€ hooks/
â”‚   â”œâ”€â”€ useWorkflow.ts           # Workflow state management
â”‚   â”œâ”€â”€ useNodeConfig.ts         # Node configuration helpers
â”‚   â”œâ”€â”€ usePlugins.ts            # Fetch plugins from API
â”‚   â””â”€â”€ useExecution.ts          # Workflow execution hooks
â”‚
â”œâ”€â”€ stores/
â”‚   â””â”€â”€ workflowStore.ts         # Zustand store for workflow state
â”‚
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ plugins.ts           # Plugin API calls
â”‚   â”‚   â””â”€â”€ workflows.ts         # Workflow API calls
â”‚   â”‚
â”‚   â””â”€â”€ workflow/
â”‚       â”œâ”€â”€ validation.ts        # Client-side workflow validation
â”‚       â”œâ”€â”€ serialization.ts     # Workflow to/from JSON
â”‚       â””â”€â”€ capabilities.ts      # Capabilities propagation logic
â”‚
â””â”€â”€ types/
    â”œâ”€â”€ workflow.ts              # Workflow, Node, Edge types
    â”œâ”€â”€ plugin.ts                # Plugin schema types
    â””â”€â”€ execution.ts             # Execution status types
```

---

## API Contracts

### Get Available Plugins

```
GET /api/v1/plugins?problem_type=classification
```

Response:
```
{
  "models": [
    {
      "slug": "random_forest",
      "name": "Random Forest",
      "icon": "ğŸŒ²",
      "description": "Ensemble of decision trees",
      "problem_types": ["classification", "regression"],
      "category": "ensemble"
    }
  ],
  "preprocessing": [
    {
      "slug": "fill_missing_mean",
      "name": "Fill Missing (Mean)",
      "category": "missing_values",
      "applies_to": ["numeric"]
    }
  ]
}
```

### Get Plugin Details

```
GET /api/v1/plugins/models/random_forest
```

Response:
```
{
  "slug": "random_forest",
  "name": "Random Forest",
  "hyperparameters": {
    "main": [
      { "key": "n_estimators", "type": "int", "default": 100, "min": 10, "max": 500 },
      { "key": "max_depth", "type": "int", "default": null, "min": 1, "max": 50, "nullable": true }
    ],
    "advanced": [
      { "key": "min_samples_split", "type": "int", "default": 2, "min": 2, "max": 20 }
    ]
  },
  "supported_metrics": ["accuracy", "f1_score", "precision", "recall", "roc_auc", "confusion_matrix"],
  "default_metrics": ["accuracy", "f1_score", "confusion_matrix"],
  "supported_plots": ["feature_importance", "confusion_matrix", "roc_curve", "learning_curve", "shap_summary"],
  "default_plots": ["feature_importance", "confusion_matrix"]
}
```

### Execute Workflow

```
POST /api/v1/workflows/execute
```

Request:
```
{
  "workflow_id": "uuid",
  "nodes": [
    { "id": "node-1", "type": "dataset", "config": { "dataset_id": "abc", "target_column": "label", "problem_type": "classification" } },
    { "id": "node-2", "type": "preprocessing", "config": { "operations": [...] } },
    { "id": "node-3", "type": "split", "config": { "test_size": 0.2, "stratify": true, "shuffle": true, "random_seed": 42 } },
    { "id": "node-4", "type": "model", "config": { "algorithm": "random_forest", "hyperparameters": {...}, "use_cv": true, "cv_folds": 5 } },
    { "id": "node-5", "type": "evaluate", "config": { "metrics": ["accuracy", "f1_score"] } },
    { "id": "node-6", "type": "visualize", "config": { "plots": ["confusion_matrix", "feature_importance"] } }
  ],
  "edges": [
    { "source": "node-1", "target": "node-2" },
    { "source": "node-2", "target": "node-3" },
    { "source": "node-3", "target": "node-4" },
    { "source": "node-4", "target": "node-5" },
    { "source": "node-5", "target": "node-6" }
  ]
}
```

Response:
```
{
  "job_id": "uuid",
  "status": "queued",
  "estimated_time": 120
}
```

### Get Execution Status (WebSocket)

```
WS /api/v1/workflows/execute/{job_id}/stream
```

Messages:
```
{ "node_id": "node-1", "status": "running" }
{ "node_id": "node-1", "status": "completed", "duration": 1.2 }
{ "node_id": "node-2", "status": "running" }
...
{ "type": "complete", "results": { "metrics": {...}, "artifacts": [...] } }
```

---

## Workflow Execution Flow

### Sequence Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Frontend â”‚     â”‚   API    â”‚     â”‚  Redis   â”‚     â”‚  Worker  â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
     â”‚                â”‚                â”‚                â”‚
     â”‚ Execute        â”‚                â”‚                â”‚
     â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚                â”‚                â”‚
     â”‚                â”‚ Validate       â”‚                â”‚
     â”‚                â”‚ workflow       â”‚                â”‚
     â”‚                â”‚                â”‚                â”‚
     â”‚                â”‚ Queue job      â”‚                â”‚
     â”‚                â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚                â”‚
     â”‚                â”‚                â”‚                â”‚
     â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                â”‚                â”‚
     â”‚ job_id         â”‚                â”‚                â”‚
     â”‚                â”‚                â”‚ Pop job        â”‚
     â”‚                â”‚                â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
     â”‚                â”‚                â”‚                â”‚
     â”‚ Connect WS     â”‚                â”‚ Execute        â”‚
     â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚                â”‚ Dataset        â”‚
     â”‚                â”‚                â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚
     â”‚                â”‚                â”‚                â”‚
     â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
     â”‚ node-1 running â”‚ Publish status â”‚                â”‚
     â”‚                â”‚                â”‚                â”‚
     â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
     â”‚ node-1 done    â”‚                â”‚ Execute        â”‚
     â”‚                â”‚                â”‚ Preprocess     â”‚
     â”‚                â”‚                â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚
     â”‚                â”‚                â”‚                â”‚
     â”‚    ...continues for each node...                â”‚
     â”‚                â”‚                â”‚                â”‚
     â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
     â”‚ complete       â”‚                â”‚ Store results  â”‚
     â”‚ + results      â”‚                â”‚ in DB + R2     â”‚
     â”‚                â”‚                â”‚                â”‚
```

### Worker Execution Steps

1. **Load Dataset**: Fetch from storage, load into DataFrame
2. **Preprocess**: Apply operations in order using preprocessing registry
3. **Split**: Train/test split with configured options
4. **Train Model**: 
   - Instantiate plugin with hyperparameters
   - If CV: Run cross-validation
   - If Optuna: Run hyperparameter search
   - Train final model
5. **Evaluate**: Execute selected metrics from plugin's supported list
6. **Visualize**: Generate selected plots from plugin's supported list
7. **Store Results**: Save model artifact, metrics, and plot images to storage

---

## Implementation Phases

### Phase 1: Backend Plugin Foundation
- Create plugin base class and registry
- Implement 3-4 initial model plugins (Random Forest, Logistic Regression, XGBoost, Decision Tree)
- Create shared evaluators and visualizers
- Implement preprocessing registry and methods
- Create workflow execution endpoint

### Phase 2: Frontend Inspector Optimization
- Refactor node components to use consistent patterns
- Create reusable inspector field components
- Implement dynamic field rendering from plugin schemas
- Add capabilities propagation between nodes
- Implement workflow serialization/deserialization

### Phase 3: Execution Integration
- Connect frontend to execution API
- Implement WebSocket status updates
- Add execution progress UI on canvas
- Create results display panel

### Phase 4: Polish & Testing
- Add validation warnings and error handling
- Implement cost calculation
- Add execution history
- Write integration tests

---

## Summary

The plugin system provides a scalable, maintainable architecture where:

1. **Backend plugins** define complete algorithm behavior (hyperparameters, training, evaluation, visualization)
2. **Shared libraries** provide common evaluation and visualization functions
3. **Frontend** dynamically renders inspector panels based on plugin schemas
4. **Capabilities** flow downstream from Model to Evaluate/Visualize nodes
5. **Execution** happens asynchronously via workers with real-time status updates

This design allows adding new algorithms by simply creating a new plugin fileâ€”no changes needed to frontend code, evaluation logic, or visualization code.
